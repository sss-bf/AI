# from langchain_community.chat_models import ChatOpenAI
from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
import os
import replicate
import requests

from src.utils.datetime_helper import CurrentDateTime
from src.utils.image_file_helper import ImageFileHelper
import json

from io import BytesIO
import IPython
import json
import os
from PIL import Image
import requests
import time
# from google.colab import output
import math
from dotenv import load_dotenv

load_dotenv()

STABILITY_KEY = os.getenv("STABILITY_KEY")

def send_generation_request(
    host,
    params,
    files = None
):
    headers = {
        "Accept": "image/*",
        "Authorization": f"Bearer {STABILITY_KEY}"
    }

    if files is None:
        files = {}

    # Encode parameters
    image = params.pop("image", None)
    mask = params.pop("mask", None)
    if image is not None and image != '':
        files["image"] = open(image, 'rb')
    if mask is not None and mask != '':
        files["mask"] = open(mask, 'rb')
    if len(files)==0:
        files["none"] = ''

    # Send request
    print(f"Sending REST request to {host}...")
    response = requests.post(
        host,
        headers=headers,
        files=files,
        data=params
    )
    if not response.ok:
        raise Exception(f"HTTP {response.status_code}: {response.text}")

    return response

def send_async_generation_request(
    host,
    params,
    files = None
):
    headers = {
        "Accept": "application/json",
        "Authorization": f"Bearer {STABILITY_KEY}"
    }

    if files is None:
        files = {}

    # Encode parameters
    image = params.pop("image", None)
    mask = params.pop("mask", None)
    if image is not None and image != '':
        files["image"] = open(image, 'rb')
    if mask is not None and mask != '':
        files["mask"] = open(mask, 'rb')
    if len(files)==0:
        files["none"] = ''

    # Send request
    print(f"Sending REST request to {host}...")
    response = requests.post(
        host,
        headers=headers,
        files=files,
        data=params
    )
    if not response.ok:
        raise Exception(f"HTTP {response.status_code}: {response.text}")

    # Process async response
    response_dict = json.loads(response.text)
    generation_id = response_dict.get("id", None)
    assert generation_id is not None, "Expected id in response"

    # Loop until result or timeout
    timeout = int(os.getenv("WORKER_TIMEOUT", 500))
    start = time.time()
    status_code = 202
    while status_code == 202:
        print(f"Polling results at https://api.stability.ai/v2beta/results/{generation_id}")
        response = requests.get(
            f"https://api.stability.ai/v2beta/results/{generation_id}",
            headers={
                **headers,
                "Accept": "*/*"
            },
        )

        if not response.ok:
            raise Exception(f"HTTP {response.status_code}: {response.text}")
        status_code = response.status_code
        time.sleep(10)
        if time.time() - start > timeout:
            raise Exception(f"Timeout after {timeout} seconds")

    return response

class OpenAIModel:
    def __init__(self):
        openai_api_key = os.getenv("OPENAI_API_KEY")
        self.open_ai_model = ChatOpenAI(model = "gpt-4o", temperature = 0.7, openai_api_key = openai_api_key)
        self.history = ""
        self.last_image_url = ""
        self.url = "https://api.developer.pixelcut.ai/v1/generate-background"

    def request_guide(self, image_url, user_request):
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì¦ˆ)
        image_url = self._preprocess_image(image_url)

        guide_text = self._create_guide_text(image_url, user_request)

        image_prompt = guide_text
        if self._is_request_detail_guide(image_url, user_request):
            image_prompt = self._create_image_prompt(self.last_image_url, user_request)
        elif self._is_request_image_guide(image_url, user_request):
            self.last_image_url = ""
            image_prompt = self._create_image_prompt(image_url, user_request)
        else:
            image_prompt = self._create_image_prompt(image_url, user_request)

        guide_image_url = self._create_guide_image_url(image_prompt)
        self.last_image_url = guide_image_url
        return guide_text, guide_image_url
    
    def _preprocess_image(self, image_url):
        imageFileHelper = ImageFileHelper()
        image_file_path = imageFileHelper.save_image_from_url(image_url)
        print(image_file_path)
        imgbb_api_key = os.getenv("IMGBB_API_KEY")
        IMAGE_PATH = image_file_path
        # ğŸ”¹ API ìš”ì²­ URL
        UPLOAD_URL = "https://api.imgbb.com/1/upload"

        # ğŸ”¹ ì´ë¯¸ì§€ ì—…ë¡œë“œ ìš”ì²­
        with open(IMAGE_PATH, "rb") as file:
            response = requests.post(UPLOAD_URL, data={"key": imgbb_api_key}, files={"image": file})

        # ğŸ”¹ ì‘ë‹µ ê²°ê³¼ í™•ì¸
        if response.status_code == 200:
            result = response.json()
            image_url = result["data"]["url"]
            print(f"âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ! URL: {image_url}")
        else:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨! ì˜¤ë¥˜ ì½”ë“œ: {response.status_code}, ë©”ì‹œì§€: {response.text}")

        return image_url
    
    def _create_guide_text(self, image_url, user_request):
        message = self._create_message(image_url, user_request)
        response = self.open_ai_model.invoke(message)
        guide_text = response.content
        if self._is_request_image_guide(image_url, user_request):
            self.history = ""
        else:
            self.history = guide_text
        return guide_text

    def _create_message(self, image_url, user_request):
        messages = []

        if self._is_request_image_guide(image_url, user_request): # Imageì™€ Textê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš° : ì‚¬ì§„ì— ì˜ë„ë¥¼ ì¶”ê°€í•˜ì—¬ ê°€ì´ë“œ ìƒì„±
            print("Both", bool(image_url), bool(user_request))
            messages = self._create_image_guide(image_url, user_request)
           
        elif self._is_request_image_feedback(image_url, user_request): # Imageë§Œ ë“¤ì–´ì˜¨ ê²½ìš° : ì´ì „ ê°€ì´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í˜„ì¬ ì´ë¯¸ì§€ì˜ ê°€ì´ë“œ ìƒì„±
            print("Image Only", bool(image_url), bool(user_request))
            messages = self._create_image_feedback(image_url, user_request)
            
        elif self._is_request_detail_guide(image_url, user_request): # Textë§Œ ë“¤ì–´ì˜¨ ê²½ìš° : ì´ì „ ì‚¬ì§„ê³¼ ì´ì „ ê°€ì´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë” ì„¸ë¶€ì ì¸ ê°€ì´ë“œ ìƒì„±
            print("Text Only", bool(image_url), bool(user_request))
            messages = self._create_detail_guide(image_url, user_request)

        else: # ë‘˜ ë‹¤ ì•ˆë“¤ì–´ì˜¨ ê²½ìš°
            raise Exception("Critical Error!!!!! ë°œìƒí•˜ë©´ ì•ˆë˜ëŠ” ì¼ì´ ë°œìƒí–ˆë‹¤!!!!")

        return messages
    
    def _is_request_image_guide(self, image_url, user_request):
        return bool(image_url and user_request)

    def _is_request_image_feedback(self, image_url, user_request):
        return bool(image_url and not user_request)

    def _is_request_detail_guide(self, image_url, user_request):
        return bool(not image_url and user_request)
    
    def _create_image_guide(self, image_url, user_request):
        prompt = f"""
            ì¸ë¬¼ ì‚¬ì§„ì„ ë¶„ì„í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•©ë‹ˆë‹¤. ì‚¬ìš©ìê°€ '{user_request}'ë¼ê³  ìš”ì²­í–ˆìŠµë‹ˆë‹¤. 
            ìš°ì„ , í˜„ì¬ ì‚¬ì§„ì´ ì–´ë–¤ì§€, ì˜ ì°ì—ˆëŠ”ì§€ ê°„ë‹¨íˆ íŒë‹¨í•´ì£¼ì„¸ìš”.
            êµ¬ë„ ì¡°ì •, í¬ì¦ˆ&í‘œì •, ì¹´ë©”ë¼ ì•µê¸€, ê´‘ì›ì˜ ìœ„ì¹˜, ì¤Œì¸Â·ì¤Œì•„ì›ƒ ë“±ì˜ ê´€ì ì—ì„œ ê°œì„ ì´ í•„ìš”í•œ ì ì´ ìˆëŠ” ìš”ì†Œì— ëŒ€í•´ì„œë§Œ ì„¤ëª…í•´ì£¼ê³ , ê°œì„ í•  í•„ìš”ê°€ ì—†ëŠ” ìš”ì†ŒëŠ” ìƒëµí•´ì£¼ì„¸ìš”.
        """
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì‚¬ì§„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•œ ë§íˆ¬ë¡œ ì•Œë ¤ì£¼ì„¸ìš”."),
            HumanMessage(content=[
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": image_url}}
            ])
        ]
        return messages

    def _create_image_feedback(self, image_url, user_request):
        prompt = f"""
            ì‚¬ìš©ìê°€ ìƒˆë¡œìš´ ì‚¬ì§„ì„ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤.
            ê¸°ì¡´ í”¼ë“œë°±: {self.history}
            ìƒˆë¡œìš´ ì‚¬ì§„ì´ í”¼ë“œë°±ì„ ì˜ ë°˜ì˜í–ˆë‹¤ë©´ ì¹­ì°¬ì˜ ê¸€ì„ ë‚¨ê²¨ì£¼ì„¸ìš”. ë°±ì  ë§Œì ì˜ ëª‡ ì ì¸ì§€ ì•Œë ¤ì£¼ì„¸ìš”.
            ì¶”ê°€ì ìœ¼ë¡œ ìˆ˜ì •ì´ í•„ìš”í•œ ë¶€ë¶„ì´ ìˆë‹¤ë©´ ì•Œë ¤ì£¼ì„¸ìš”.
        """
            
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì‚¬ì§„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•œ ë§íˆ¬ë¡œ ì•Œë ¤ì£¼ì„¸ìš”."),
            HumanMessage(content=[
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": image_url}}
            ])
        ]
        return messages

    def _create_detail_guide(self, image_url, user_request):
        prompt = f"""
            ì‚¬ìš©ìê°€ '{user_request}'ë¼ê³  ì¶”ê°€ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. \n
            {self.history}
            ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ í•´ì£¼ì„¸ìš”.
            ì´ì „ì— ë°›ì€ í”¼ë“œë°±ê³¼ ì‚¬ìš©ìì˜ ì¶”ê°€ ìš”ì²­ì„ ë°˜ì˜í•˜ì—¬, í˜„ì¬ ì‚¬ì§„ì—ì„œ ì–´ë–»ê²Œ ìˆ˜ì •í•´ì•¼í• ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.\n
        """
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì‚¬ì§„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•œ ë§íˆ¬ë¡œ ì•Œë ¤ì£¼ì„¸ìš”."),
            HumanMessage(content=prompt)
        ]

        return messages
    
    def _create_image_prompt(self, image_url, user_request):
        prompt = f"""
            Describe the size of the image and the size of the subject within it.
            Provide a highly detailed description of the subjectâ€™s clothing, including the top, bottom, and shoes, specifying color, material, and fit.
            Describe the weather and background in great detail.
            Give a comprehensive description of the entire scene so that even someone who has never seen the photo can fully visualize it.

            Based on {self.history}, describe the best camera angle and composition for the subject, such as head shot, upper body shot, half body shot, full body shot, birdâ€™s eye shot, drone shot, high angle shot, from above, knee shot, etc.
            Specify the exact placement and proportion of the subject within the rule of thirds, providing precise measurements (e.g., lower center of the frame, occupying 1/2 of the image in a smaller composition).

            To satisfy {user_request}, describe in detail the ideal facial expression and pose the subject should take.

            Write a highly detailed description of the entire scene within approximately 1000 characters so that anyone can accurately visualize it.
            """
        
        messages = [
            SystemMessage(content="You are someone who describes photographs. Describe the image so vividly and precisely that even someone who has not seen it can perfectly visualize it in their mind."),
            HumanMessage(content=[
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": image_url}}
            ])
        ]

        response = self.open_ai_model.invoke(messages)
        image_prompt = response.content
        self.history = image_prompt
        return image_prompt

    def _create_guide_image_url(self,  prompt):
        input = {
            "prompt": f'{prompt}\n ìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ 3:4 ë¹„ìœ¨ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì¤˜.',
            "aspect_ratio": "3:4",
            "prompt_upsampling": True,
            "width": 270,
            "height": 360
        }

        output = replicate.run(
            "black-forest-labs/flux-1.1-pro",
            input = input
        )

        directory = "./result_histories"
        if not os.path.isdir(directory):
            os.makedirs(directory)

        image_file_path = f"{directory}/{CurrentDateTime()}.jpg"
        with open(image_file_path, "wb") as file:
            file.write(output.read())

        imgbb_api_key = os.getenv("IMGBB_API_KEY")
        IMAGE_PATH = image_file_path
        # ğŸ”¹ API ìš”ì²­ URL
        UPLOAD_URL = "https://api.imgbb.com/1/upload"

        # ğŸ”¹ ì´ë¯¸ì§€ ì—…ë¡œë“œ ìš”ì²­
        with open(IMAGE_PATH, "rb") as file:
            response = requests.post(UPLOAD_URL, data={"key": imgbb_api_key}, files={"image": file})

        # ğŸ”¹ ì‘ë‹µ ê²°ê³¼ í™•ì¸
        if response.status_code == 200:
            result = response.json()
            image_url = result["data"]["url"]
            print(f"âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ! URL: {image_url}")
        else:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨! ì˜¤ë¥˜ ì½”ë“œ: {response.status_code}, ë©”ì‹œì§€: {response.text}")

        return image_url

    def request_retouching(self, image_url, user_request):
        instruction_text = self._create_product_instruction(image_url, user_request)
        background_image_prompt = self._create_background_prompt(image_url, user_request)
        background_image_url = self._create_image_background_url_stable(image_url, background_image_prompt)
        return instruction_text, background_image_url

    # ìƒí’ˆ ì†Œê°œê¸€ ìƒì„±
    def _create_product_instruction(self, image_url, user_request):
        prompt = f"""
            Your task is to:

            1. Analyze the input image of the product
            2. Consider the product information provided by {user_request}
            3. Understand the user's intention in {user_request}
            4. Create compelling, concise product copy that:
            - Highlights the product's key features and benefits
            - Appeals to the emotional needs of potential buyers
            - Uses engaging, persuasive language
            - Is appropriate for social media or secondhand marketplace listings
            - Creates urgency and desire

            Your copy should be brief yet impactful (50-100 words), include emotive language, and emphasize what makes this product special in korean. Format with attention-grabbing headlines and use short paragraphs or bullet points for readability. Focus on creating text that will make someone stop scrolling and want to buy immediately.
            """
        
        messages = [
            SystemMessage(content="You are a product copywriting specialist for social media and secondhand marketplaces."),
            HumanMessage(content=[
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": image_url}}
            ])
        ]

        response = self.open_ai_model.invoke(messages)
        instruction_prompt = response.content
        self.history = instruction_prompt
        return instruction_prompt

    # ë°°ê²½ ì´ë¯¸ì§€ êµì²´ë¥¼ ìœ„í•œ ë°°ê²½ í”„ë¡¬í”„íŠ¸ ìƒì„±
    def _create_background_prompt(self, image_url, user_request):
        prompt = f"""
            Your task is to:

            1. Analyze the input image containing a product
            2. Understand {user_request}
            3. Return ONLY ONE highly descriptive background prompt that:
            - Complements the product's aesthetics (color, style, shape)
            - Aligns with the user's stated purpose
            - Creates a contextually appropriate setting
            - Uses vivid, specific language with appropriate adjectives
            - Maintains professional product photography standards

            Your response should be ONLY the background prompt itself - no explanations, no options, no additional text. Keep the prompt under 50 words and focus on creating a photorealistic, attractive environment that will enhance the product's appeal.
            """
        
        messages = [
            SystemMessage(content="You are a specialized prompt creator for product photography backgrounds."),
            HumanMessage(content=[
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": image_url}}
            ])
        ]

        response = self.open_ai_model.invoke(messages)
        background_prompt = response.content
        self.history = background_prompt
        return background_prompt

    # ì‚¬ìš©ìì˜ë„ì™€ ë°°ê²½ í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ë°°ê²½ êµì²´ëœ ì´ë¯¸ì§€(url) ìƒì„±
    def _create_image_background_url(self, image_url, background_prompt):
        payload = json.dumps({
        "image_url": image_url,
        "image_transform": {
            "scale": 1,
            "x_center": 0.5,
            "y_center": 0.5
        },
        "prompt": background_prompt,
        "negative_prompt": ""
        })
        headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json',
        'X-API-KEY': 'sk_bb463e61da7043139c11db8365cb3521' # pixiecut api
        }

        image_url = requests.request("POST", self.url, headers=headers, data=payload)

        return image_url.text

    def _create_image_background_url_peb(self, image_url, background_prompt):

        import base64
        import io
        import time

        import requests
        from PIL import Image

        print(background_prompt)
        

        endpoint_url = "https://api.pebblely.com/remove-background/v1/"

        response = requests.post(
        endpoint_url,
        headers={
            "Content-Type": "application/json",
            "X-Pebblely-Access-Token": "b7064b83-4fea-4fa0-ab4c-0a20eb4306e1",
        },
        json={
            "image": image_url,
        }
        )
        no_bg_image_b64 = response.json()["data"]
        no_bg_image_encoded = no_bg_image_b64.encode("utf-8")
        no_bg_image_bytes = io.BytesIO(base64.b64decode(no_bg_image_encoded))
        no_bg_image = Image.open(no_bg_image_bytes)
        no_bg_image.save("no_bg_image.png")

        time.sleep(1)

        endpoint_url = "https://api.pebblely.com/create-background/v2/"

        response = requests.post(
            endpoint_url,
            headers={
                "Content-Type": "application/json",
                "X-Pebblely-Access-Token": "b7064b83-4fea-4fa0-ab4c-0a20eb4306e1",
            },
            json={
                "images": [f"data:image/png;base64,{no_bg_image_b64}"],
                "theme": "Surprise me",
                "description": background_prompt,
                "transforms": [{
                    "scale_x": 1,
                    "scale_y": 1,
                    "x": 0,
                    "y": 0,
                    "angle": 0
                }]
            }
        )
        print(response)
        # Process Base64 output and save locally 
        image_b64 = response.json()["data"]
        image_encoded = image_b64.encode("utf-8")
        image_bytes = io.BytesIO(base64.b64decode(image_encoded))
        image = Image.open(image_bytes)
        image.save("gen_bg_image.jpg")

        return image

    def _create_image_background_url_stable(self, image_url, background_prompt):

        imageFileHelper = ImageFileHelper()

        original_image_file_name = imageFileHelper.save_image_from_url(image_url)

        # TODO: URL -> ì´ë¯¸ì§€ íŒ¨ìŠ¤ë¡œ ë°”ê¿”ì•¼ í•¨.
        subject_image = original_image_file_name

        # ì´ë¯¸ì§€ ë¡œë“œ
        img = Image.open(subject_image)
        width, height = img.size
        total_pixels = width * height

        # ìµœëŒ€ í—ˆìš© í”½ì…€ ìˆ˜
        max_pixels = 9437184

        # í¬ê¸°ê°€ ì´ˆê³¼ë˜ë©´ ì¡°ì •
        if total_pixels > max_pixels:
            scale_factor = math.sqrt(max_pixels / total_pixels)
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)

            # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
            img = img.resize((new_width, new_height), Image.LANCZOS)

            # ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€ ì €ì¥
            resized_path = "/content/resized_subject.jpg"
            img.save(resized_path)

            # ê²½ë¡œ ë³€ê²½
            subject_image = resized_path



        # subject_image = resized_path #{type:"string"}
        #Use one or both of `background_prompt` string or `background_reference` image
        background_prompt = "A clear, refreshing summer day at a picnic spot in nature with blue mountains and a crystal-clear lake, where hikers with beads of sweat enjoy cool Torreta beverages in glass bottles, refreshing bubbles rising in the drink with cool water droplets condensing on the bottle surface, sunlight shining through the beverage creating sparkling reflections, atmosphere conveying freshness and rejuvenation" # {type:"string"}
        background_reference = "" #{type:"string"}

        # Optional inputs:
        foreground_prompt = "" #{type:"string"}
        negative_prompt = "" #{type:"string"}
        preserve_original_subject = 0.6 #{min:0, max:1, step:0.05}
        original_background_depth =  0.1 #{min:0, max:1, step:0.05}
        keep_original_background = False #{type:"boolean"}

        #Use `light_source_strength` with a `light_reference` image or a `light_source_direction`
        light_source_strength = 0.3 #{min:0, max:1, step:0.05}
        light_reference = "" #{type:"string"}
        light_source_direction = "none" #["none", "left", "right", "above", "below"]


        seed = 0 #{type:"integer"}
        output_format = "jpeg" #["webp", "jpeg", "png"]

        host = f"https://api.stability.ai/v2beta/stable-image/edit/replace-background-and-relight"

        files = {}
        files["subject_image"] = open(subject_image, 'rb')
        if background_reference:
            files["background_reference"] = open(background_reference, 'rb')
        if light_reference:
            files["light_reference"] = open(light_reference, 'rb')

        params = {
            "output_format": output_format,
            "background_prompt": background_prompt,
            "foreground_prompt": foreground_prompt,
            "negative_prompt": negative_prompt,
            "preserve_original_subject": preserve_original_subject,
            "original_background_depth": original_background_depth,
            "keep_original_background": keep_original_background,
            "seed": seed
        }
        if light_source_direction != "none":
            params["light_source_direction"] = light_source_direction

        # light_source_strength is only valid when using light_source_direction or light_reference
        if light_source_direction != "none" or light_reference != '':
            params["light_source_strength"] = light_source_strength

        response = send_async_generation_request(
            host,
            params,
            files=files
        )

        # Decode response
        output_image = response.content
        finish_reason = response.headers.get("finish-reason")
        seed = response.headers.get("seed")

        # Check for NSFW classification
        if finish_reason == 'CONTENT_FILTERED':
            raise Warning("Generation failed NSFW classifier")

        # Save and display result
        filename, _ = os.path.splitext(os.path.basename(subject_image))
        edited = f"edited_{filename}_{seed}.{output_format}"
        with open(edited, "wb") as f:
            f.write(output_image)
        print(f"Saved image {edited}")

        result_image = Image.open(edited)

        imgbb_api_key = os.getenv("IMGBB_API_KEY")
        IMAGE_PATH = edited
        # ğŸ”¹ API ìš”ì²­ URL
        UPLOAD_URL = "https://api.imgbb.com/1/upload"

        # ğŸ”¹ ì´ë¯¸ì§€ ì—…ë¡œë“œ ìš”ì²­
        with open(IMAGE_PATH, "rb") as file:
            response = requests.post(UPLOAD_URL, data={"key": imgbb_api_key}, files={"image": file})

        # ğŸ”¹ ì‘ë‹µ ê²°ê³¼ í™•ì¸
        if response.status_code == 200:
            result = response.json()
            image_url = result["data"]["url"]
            print(f"âœ… ì´ë¯¸ì§€ ì—…ë¡œë“œ ì„±ê³µ! URL: {image_url}")
        else:
            print(f"âŒ ì—…ë¡œë“œ ì‹¤íŒ¨! ì˜¤ë¥˜ ì½”ë“œ: {response.status_code}, ë©”ì‹œì§€: {response.text}")

        return image_url
